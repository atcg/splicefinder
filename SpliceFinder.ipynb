{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splicefinder\n",
    "======\n",
    "\n",
    "This is the walkthrough and code that accompanies \"Conservative prediction of intron splice sites for the design of exon-capture arrays.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 1: Download mouse data from Ensembl\n",
    "\n",
    "_________________\n",
    "\n",
    "Connect to the server, navigate to the proper folder, and download data in bash:\n",
    "\n",
    "```bash\n",
    "ssh maven\n",
    "cd /mnt/Data1/spliceFinder\n",
    "mkdir ensembl\n",
    "cd ensembl\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz\n",
    "\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/mus_musculus/cdna/README\n",
    "\n",
    "gunzip Mus_musculus.GRCm38.cdna.all.fa.gz\n",
    "```\n",
    "\n",
    "After downloading the data, `get_fasta_lengths.py --input Mus_musculus.GRCm38.cdna.all.fa` gives the following output:\n",
    "\n",
    "```text\n",
    "Reads:\t\t90,891\n",
    "Bp:\t\t168,812,502\n",
    "Avg. len:\t1,857.30712612\n",
    "STDERR len:\t6.5011432467\n",
    "Min. len:\t9\n",
    "Max. len:\t106,824\n",
    "Median len:\t1,078.0\n",
    "Contigs > 1kb:\t47,261\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These represent the latest set of mouse cDNAs from ENSEMBL. We are first going to randomly subset these into fewer than 90,891, because we are going to run many analyses on these sets, mapping to multiple genomes (which can be slow). Let's see what they look like:\n",
    "\n",
    "```text\n",
    "head --lines 6 Mus_musculus.GRCm38.cdna.all.fa\n",
    ">ENSMUST00000196221 havana_ig_gene:known chromosome:GRCm38:14:54113468:54113476:1 gene:ENSMUSG00000096749 gene_biotype:TR_D_gene transcript_biotype:TR_D_gene\n",
    "ATGGCATAT\n",
    ">ENSMUST00000179664 ensembl_ig_gene:known chromosome:GRCm38:14:54113468:54113478:1 gene:ENSMUSG00000096749 gene_biotype:TR_D_gene transcript_biotype:TR_D_gene\n",
    "ATGGCATATCA\n",
    ">ENSMUST00000177564 ensembl_havana_ig_gene:known chromosome:GRCm38:14:54122226:54122241:1 gene:ENSMUSG00000096176 gene_biotype:TR_D_gene transcript_biotype:TR_D_gene\n",
    "ATCGGAGGGATACGAG\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this output tells us a few things. First of all, some of the transcripts are extremely short. Since the purpose of this method is to infer contiguous genomic sequence chunks long enough to use target enrichment array design, we know we'll want to filter out all cDNAs that are too short to actually yield a target. We'll arbitrarily set this limit at 200bp for now. The following script will output all sequences longer than 199bp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl\n",
    "\n",
    "#filterUnder200.pl\n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use Bio::SeqIO;\n",
    "\n",
    "my $seqIn = Bio::SeqIO->new(-file => \"Mus_musculus.GRCm38.cdna.all.fa\",\n",
    "                            -format => 'fasta');\n",
    "my $seqOut = Bio::SeqIO->new(-file => \">mmGRCm38.cdna.200bpPlus.fa\",\n",
    "                             -format => \"fasta\");\n",
    "\n",
    "while (my $seq = $seqIn->next_seq()) {\n",
    "    if ($seq->length() > 199) {\n",
    "        $seqOut->write_seq($seq);\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, we have:\n",
    "\n",
    "```text\n",
    "get_fasta_lengths.py --input mmGRCm38.cdna.200bpPlus.fa \n",
    "Reads:          90,060\n",
    "Bp:             168,702,266\n",
    "Avg. len:       1,873.22080835\n",
    "STDERR len:     6.53762906167\n",
    "Min. len:       200\n",
    "Max. len:       106,824\n",
    "Median len:     1,098.0\n",
    "Contigs > 1kb:  47,261\n",
    "```\n",
    "\n",
    "That didn't very many, so we'll have to reduce further. You'll notice in the fasta headers that there is a gene name in the fourth column. Let's find out how many unique gene names there are total:\n",
    "\n",
    "```text\n",
    "grep \"gene:\" mmGRCm38.cdna.200bpPlus.fa | awk '{print $4}' | uniq -c | wc -l\n",
    "30722\n",
    "```\n",
    "\n",
    "Randomly choosing one transcript from each gene name seems like one good way to reduce the dataset without losing genomic coverage. But choosing the longest cDNA from each gene name might give us better success at mapping to other genomes. Let's do that with the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl\n",
    "\n",
    "# longestFromGenes.pl\n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use Bio::SeqIO;\n",
    "\n",
    "\n",
    "my %seqHash;\n",
    "my $seqIn1 = Bio::SeqIO->new(-file => \"mmGRCm38.cdna.200bpPlus.fa\",\n",
    "                             -format => \"fasta\");\n",
    "my $seqOut = Bio::SeqIO->new(-file => \">mmGRCm38.cdna.longestFromGenes.fa\",\n",
    "                             -format => \"fasta\");\n",
    "\n",
    "while (my $seq = $seqIn1->next_seq()) {\n",
    "    if ($seq->desc() =~ /.*gene\\:(\\S+)\\s/) {\n",
    "        # Each transcript is associated with a gene name, and has a\n",
    "        # hash value equal to its length\n",
    "        my $geneName = $1;\n",
    "        $seqHash{$geneName}{$seq->display_id()} = $seq;\n",
    "    }\n",
    "}\n",
    "\n",
    "foreach my $gene (sort keys %seqHash) {\n",
    "    my $longestID;\n",
    "    my $longestLength = 0;\n",
    "    foreach my $transcript (sort keys %{$seqHash{$gene}}) {\n",
    "        if ($seqHash{$gene}{$transcript}->length() > $longestLength) {\n",
    "            $longestID = $transcript;\n",
    "            $longestLength = $seqHash{$gene}{$transcript}->length();\n",
    "        }\n",
    "    }\n",
    "    $seqOut->write_seq($seqHash{$gene}{$longestID})\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should get the list down to 30,722, and the average length should go up (it was 1,873 bp before).\n",
    "\n",
    "```text\n",
    "get_fasta_lengths.py --input mmGRCm38.cdna.longestFromGenes.fa \n",
    "Reads:          30,722\n",
    "Bp:             73,817,860\n",
    "Avg. len:       2,402.76869995\n",
    "STDERR len:     13.0889977284\n",
    "Min. len:       200\n",
    "Max. len:       106,824\n",
    "Median len:     1,734.0\n",
    "Contigs > 1kb:  20,279\n",
    "```\n",
    "\n",
    "Looking good! I think 30,722 transcripts is still a little high though, so I will subset the dataset down to 10,000 transcripts randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use List::Util qw/shuffle/;\n",
    "\n",
    "#random10k.pl\n",
    "\n",
    "my $seqIn = Bio::SeqIO->new(-file => \"mmGRCm38.cdna.longestFromGenes.fa\",\n",
    "                            -format => \"fasta\");\n",
    "my $seqOut = Bio::SeqIO->new(-file => \">mmGRCm38.cdna.rand10kLongest.fa\",\n",
    "                            -format => \"fasta\");\n",
    "\n",
    "my @seqArray;\n",
    "while (my $seq = $seqIn->next_seq()) {\n",
    "    push(@seqArray, $seq);\n",
    "}\n",
    "\n",
    "my @shuffledSeqs = shuffle(@seqArray);\n",
    "\n",
    "my $counter = 0;\n",
    "while ($counter < 10000) {\n",
    "    $seqOut->write_seq($shuffledSeqs[$counter]);\n",
    "    $counter++;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That should give us 10,000 transcripts from 10,000 distinct genes scattered throughout the mouse genome.\n",
    "\n",
    "```text\n",
    "get_fasta_lengths.py --input mmGRCm38.cdna.rand10kLongest.fa\n",
    "Reads:\t\t10,000\n",
    "Bp:\t\t23,940,240\n",
    "Avg. len:\t2,394.024\n",
    "STDERR len:\t21.8914472689\n",
    "Min. len:\t200\n",
    "Max. len:\t22,489\n",
    "Median len:\t1,732.0\n",
    "Contigs > 1kb:\t6,651\n",
    "```\n",
    "\n",
    "Excellent. Now we're ready to set up some mapping. In this experiment, we're going to want to map to approximately 10 genomes of varying sequence divergence from the mouse genome. For now, let's try the following genomes:\n",
    "  1. Rat (_Rattus norvegicus_)\n",
    "  2. Human (_Homo sapiens_)\n",
    "  3. Pig (_Sus scrofa_)\n",
    "  4. Elephant (_Loxodonta_africana_)\n",
    "  5. Playtpus (_Ornithorynchus anatinus_)\n",
    "  6. Chicken (_Gallus gallus_)\n",
    "  7. _Xenopus tropicalis_\n",
    "  8. _Anolis carolinensis_\n",
    "  9. Coelacanth (_Latimeria chalumnae_)\n",
    "  10. Puffer fish (_Takifugu rubripes_)\n",
    "  11. Sea lamprey (*Petromyzon marinus*)\n",
    "  12. Sea urchin (*Strongylocentrotus purpuratus*)\n",
    "\n",
    "\n",
    "Let's download those genomes, getting the unmasked primary assembly if possible, otherwise taking the unmasked top-level assembly:\n",
    "\n",
    "```bash\n",
    "mkdir genomes\n",
    "cd genomes\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/rattus_norvegicus/dna/Rattus_norvegicus.Rnor_6.0.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/sus_scrofa/dna/Sus_scrofa.Sscrofa10.2.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/loxodonta_africana/dna/Loxodonta_africana.loxAfr3.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/ornithorhynchus_anatinus/dna/Ornithorhynchus_anatinus.OANA5.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/gallus_gallus/dna/Gallus_gallus.Galgal4.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/xenopus_tropicalis/dna/Xenopus_tropicalis.JGI_4.2.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/anolis_carolinensis/dna/Anolis_carolinensis.AnoCar2.0.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/latimeria_chalumnae/dna/Latimeria_chalumnae.LatCha1.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/takifugu_rubripes/dna/Takifugu_rubripes.FUGU4.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/petromyzon_marinus/dna/Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensemblgenomes.org/pub/metazoa/release-26/fasta/strongylocentrotus_purpuratus/dna/Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.fa.gz\n",
    "\n",
    "gunzip *.gz\n",
    "```\n",
    "\n",
    "We'll also need the full collection of protein sequences from these organisms:\n",
    "```bash\n",
    "mkdir proteins\n",
    "cd proteins\n",
    "\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/rattus_norvegicus/pep/Rattus_norvegicus.Rnor_6.0.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/homo_sapiens/pep/Homo_sapiens.GRCh38.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/sus_scrofa/pep/Sus_scrofa.Sscrofa10.2.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/loxodonta_africana/pep/Loxodonta_africana.loxAfr3.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/ornithorhynchus_anatinus/pep/Ornithorhynchus_anatinus.OANA5.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/gallus_gallus/pep/Gallus_gallus.Galgal4.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/xenopus_tropicalis/pep/Xenopus_tropicalis.JGI_4.2.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/anolis_carolinensis/pep/Anolis_carolinensis.AnoCar2.0.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/latimeria_chalumnae/pep/Latimeria_chalumnae.LatCha1.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/takifugu_rubripes/pep/Takifugu_rubripes.FUGU4.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/petromyzon_marinus/pep/Petromyzon_marinus.Pmarinus_7.0.pep.all.fa.gz\n",
    "wget ftp://ftp.ensemblgenomes.org/pub/metazoa/release-26/fasta/strongylocentrotus_purpuratus/pep/Strongylocentrotus_purpuratus.GCA_000002235.2.26.pep.all.fa.gz\n",
    "\n",
    "gunzip *\n",
    "```\n",
    "\n",
    "We're going to use exonerate protein2genome to map all of these proteins to their respective genomes.\n",
    "```bash\n",
    "cd ../\n",
    "\n",
    "fasta2esd --softmask no Loxodonta_africana.loxAfr3.dna.toplevel.fa Loxodonta_africana.loxAfr3.dna.toplevel.esd\n",
    "fasta2esd --softmask no Ornithorhynchus_anatinus.OANA5.dna.toplevel.fa Ornithorhynchus_anatinus.OANA5.dna.toplevel.esd\n",
    "fasta2esd --softmask no Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.fa Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.esd\n",
    "fasta2esd --softmask no Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.fa Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.esd\n",
    "fasta2esd --softmask no Takifugu_rubripes.FUGU4.dna.toplevel.fa Takifugu_rubripes.FUGU4.dna.toplevel.esd\n",
    "fasta2esd --softmask no Latimeria_chalumnae.LatCha1.dna.toplevel.fa Latimeria_chalumnae.LatCha1.dna.toplevel.esd\n",
    "fasta2esd --softmask no Anolis_carolinensis.AnoCar2.0.dna.toplevel.fa Anolis_carolinensis.AnoCar2.0.dna.toplevel.esd\n",
    "fasta2esd --softmask no Xenopus_tropicalis.JGI_4.2.dna.toplevel.fa Xenopus_tropicalis.JGI_4.2.dna.toplevel.esd\n",
    "fasta2esd --softmask no Gallus_gallus.Galgal4.dna.toplevel.fa Gallus_gallus.Galgal4.dna.toplevel.esd\n",
    "fasta2esd --softmask no Sus_scrofa.Sscrofa10.2.dna.toplevel.fa Sus_scrofa.Sscrofa10.2.dna.toplevel.esd\n",
    "fasta2esd --softmask no Homo_sapiens.GRCh38.dna.primary_assembly.fa Homo_sapiens.GRCh38.dna.primary_assembly.esd\n",
    "fasta2esd --softmask no Rattus_norvegicus.Rnor_6.0.dna.toplevel.fa Rattus_norvegicus.Rnor_6.0.dna.toplevel.esd\n",
    "\n",
    "esd2esi Loxodonta_africana.loxAfr3.dna.toplevel.esd Loxodonta_africana.loxAfr3.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Ornithorhynchus_anatinus.OANA5.dna.toplevel.esd Ornithorhynchus_anatinus.OANA5.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.esd Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.esd Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Takifugu_rubripes.FUGU4.dna.toplevel.esd Takifugu_rubripes.FUGU4.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Latimeria_chalumnae.LatCha1.dna.toplevel.esd Latimeria_chalumnae.LatCha1.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Anolis_carolinensis.AnoCar2.0.dna.toplevel.esd Anolis_carolinensis.AnoCar2.0.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Xenopus_tropicalis.JGI_4.2.dna.toplevel.esd Xenopus_tropicalis.JGI_4.2.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Gallus_gallus.Galgal4.dna.toplevel.esd Gallus_gallus.Galgal4.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Sus_scrofa.Sscrofa10.2.dna.toplevel.esd Sus_scrofa.Sscrofa10.2.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Homo_sapiens.GRCh38.dna.primary_assembly.esd Homo_sapiens.GRCh38.dna.primary_assembly.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Rattus_norvegicus.Rnor_6.0.dna.toplevel.esd Rattus_norvegicus.Rnor_6.0.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will take several hours. We want to map the orthologous proteins from each species to their own reference genomes. So, we will need to find the orthologous proteins from each species. First we'll make blast databases from each protein set:\n",
    "```bash\n",
    "cd proteins\n",
    "for i in *.pep.all.fa; do makeblastdb -in $i -dbtype prot; done\n",
    "```\n",
    "\n",
    "Now we'll iterate through each of the protein sets and blastx the mouse cDNAs to each, only outputting the best match:\n",
    "\n",
    "```bash\n",
    "for i in *.pep.all.fa; do OUTFILE=$i\".proteinMatches\"; blastx -db $i -query ../../mmGRCm38.cdna.rand10kLongest.fa -outfmt 6 -max_target_seqs 1 -num_threads 10 -out $OUTFILE ; done\n",
    "```\n",
    "\n",
    "The blastx'ing will also take a few hours.\n",
    "\n",
    "After the blastx is done, we'll parse the blastx results to pull out all the protein sequences that matched and store them into a new file for exonerate protein2genome mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl\n",
    "\n",
    "# pullOutMatchingProteins.pl\n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use Bio::SeqIO;\n",
    "use Bio::SearchIO;\n",
    "\n",
    "my @speciesArray = (\"Strongylocentrotus_purpuratus.GCA_000002235.2.26\", \"Petromyzon_marinus.Pmarinus_7.0\", \"Takifugu_rubripes.FUGU4\", \"Latimeria_chalumnae.LatCha1\", \"Anolis_carolinensis.AnoCar2.0\", \"Xenopus_tropicalis.JGI_4.2\", \"Gallus_gallus.Galgal4\", \"Ornithorhynchus_anatinus.OANA5\", \"Loxodonta_africana.loxAfr3\", \"Sus_scrofa.Sscrofa10.2\", \"Homo_sapiens.GRCh38\", \"Rattus_norvegicus.Rnor_6.0\");\n",
    "\n",
    "foreach my $species (@speciesArray) {\n",
    "    my $proteinFasta = $species . \".pep.all.fa\";\n",
    "    \n",
    "    my %protHash;\n",
    "    my $seqIn = Bio::SeqIO->new(-file => $proteinFasta,\n",
    "                                -format => 'fasta');\n",
    "    while (my $seq = $seqIn->next_seq()) {\n",
    "        $protHash{$seq->display_id()} = $seq;\n",
    "    }\n",
    "    \n",
    "    my $proteinOut = $species . \".pep.matching.fa\";\n",
    "    my $seqOut = Bio::SeqIO->new(-file => \">$proteinOut\",\n",
    "                                 -format => 'fasta');\n",
    "    \n",
    "    my $blastResults = $species . \".pep.all.fa.proteinMatches\";\n",
    "    open(my $blastFH, \"<\", $blastResults) or die \"Couldn't open $blastResults for reading: $!\\n\";\n",
    "    while (my $line = <$blastFH>) {\n",
    "        my @fields = split(/\\t/, $line);\n",
    "        $seqOut->write_seq($protHash{$fields[1]});\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set these aside:\n",
    "\n",
    "```bash\n",
    "mkdir matchingProteins\n",
    "mv *.pep.matching.fa matchingProteins/\n",
    "```\n",
    "\n",
    "Exonerate protein2genome is very slow unless you change some settings around, and it seems to run faster when you separate each sequence into its own file. Using only one sequence per run also has the benefit of showing you where you left off if exonerate segfaults.\n",
    "\n",
    "So we're first gonna need to separate the protein fasta files into new files, one sequence per file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl\n",
    "\n",
    "# separateProteinsIntoIndividuals.pl\n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use Bio::SeqIO;\n",
    "use Bio::SearchIO;\n",
    "\n",
    "my @speciesArray = (\"Strongylocentrotus_purpuratus.GCA_000002235.2.26\", \"Petromyzon_marinus.Pmarinus_7.0\", \"Takifugu_rubripes.FUGU4\", \"Latimeria_chalumnae.LatCha1\", \"Anolis_carolinensis.AnoCar2.0\", \"Xenopus_tropicalis.JGI_4.2\", \"Gallus_gallus.Galgal4\", \"Ornithorhynchus_anatinus.OANA5\", \"Loxodonta_africana.loxAfr3\", \"Sus_scrofa.Sscrofa10.2\", \"Homo_sapiens.GRCh38\", \"Rattus_norvegicus.Rnor_6.0\");\n",
    "\n",
    "foreach my $species (@speciesArray) {\n",
    "    # We'll have a different folder for each species\n",
    "    unless (-d $species) {\n",
    "        mkdir $species;\n",
    "    }\n",
    "    chdir $species;\n",
    "    \n",
    "    my $seqsFile = \"../\" . $species . \".pep.matching.fa\";\n",
    "\n",
    "    my $seqIn = Bio::SeqIO->new(-file => $seqsFile,\n",
    "                                -format => 'fasta');\n",
    "    \n",
    "    my $counter = 0;\n",
    "    while (my $seq = $seqIn->next_seq()) {\n",
    "        $counter++;\n",
    "        my $seqOutName = $seq->display_id() . \".pep.fasta\";\n",
    "        my $seqOut = Bio::SeqIO->new(-file => \">$seqOutName\",\n",
    "                                     -format => 'fasta');\n",
    "        \n",
    "        $seqOut->write_seq($seq);\n",
    "        \n",
    "    }\n",
    "    print $counter . \" total records processed\\n\";\n",
    "    chdir \"..\";\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some mouse transcripts might have selected the same genes from the reference set as others for the best blastx hit. This means that there should be fewer actual peptide fastas than query sequences that had positive matches in the blastx search.\n",
    "\n",
    "Now let's loop through all those sequences and align them to their proper genomes. The sending multiple queries to a single exonerate-server tends to make things segfault, so instead we'll instantiate exonerate-servers so that each thread gets its own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl\n",
    "\n",
    "# exonerateP2G.pl\n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use Bio::SeqIO;\n",
    "use Bio::SearchIO;\n",
    "use Parallel::ForkManager;\n",
    "\n",
    "my @speciesArray = (\"Strongylocentrotus_purpuratus.GCA_000002235.2.26\", \"Petromyzon_marinus.Pmarinus_7.0\", \"Takifugu_rubripes.FUGU4\", \"Latimeria_chalumnae.LatCha1\", \"Anolis_carolinensis.AnoCar2.0\", \"Xenopus_tropicalis.JGI_4.2\", \"Gallus_gallus.Galgal4\", \"Ornithorhynchus_anatinus.OANA5\", \"Loxodonta_africana.loxAfr3\", \"Sus_scrofa.Sscrofa10.2\", \"Homo_sapiens.GRCh38\", \"Rattus_norvegicus.Rnor_6.0\");\n",
    "\n",
    "\n",
    "my $portCounter = 12886; # We'll start on port 12887 and go up 29 more\n",
    "\n",
    "foreach my $species (@speciesArray) {\n",
    "    my $genomeFile = $species . \".dna.toplevel.trans.esi\";\n",
    "    \n",
    "    # We'll use a total of 15 possible threads for the forkmanager, because\n",
    "    # each thread will initiate two processes--the exonerate server and the \n",
    "    # exonerate clients. We want to use about 30 CPUs total, so set this\n",
    "    # to 15.\n",
    "    my $forkManager = Parallel::ForkManager->new(15);\n",
    "    \n",
    "    foreach my $thread (0..14) {\n",
    "        $portCounter++;\n",
    "        $forkManager->start and next;\n",
    "        chdir(\"/home/evan/spliceFinder/genomes/\");\n",
    "        system(\"exonerate-server --port $portCounter $genomeFile &\");\n",
    "        sleep(30);\n",
    "        chdir(\"proteins/matchingProteins/\");\n",
    "        chdir $species;\n",
    "        unless(-d \"exonerate\") {\n",
    "            mkdir \"exonerate\";\n",
    "        }\n",
    "\n",
    "        opendir(my $dirFH, \"./\");\n",
    "        my @files = readdir($dirFH);\n",
    "        closedir($dirFH);\n",
    "\n",
    "        my @fastaFiles;\n",
    "        foreach my $file (@files) {\n",
    "            if ($file =~ /.fasta/) {\n",
    "                push(@fastaFiles, $file);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        my $proteinsPerThread = scalar(@fastaFiles) / 15; # Decide how many proteins to provide to each thread\n",
    "\n",
    "        my $beginning = $thread * $proteinsPerThread;\n",
    "        my $end = ($thread+1) * $proteinsPerThread;\n",
    "        for (my $fileIndex=$beginning; $fileIndex < $end; $fileIndex++) {\n",
    "            my $outFileName = \"exonerate/\" . $fastaFiles[$fileIndex] . \".p2g.exonerate\";\n",
    "            system(\"exonerate $fastaFiles[$fileIndex] localhost:$portCounter --querytype protein --targettype dna --model p2g --bestn 1 --dnawordlen 12 --fsmmemory 4096 --hspfilter 50 --geneseed 250 > $outFileName\");\n",
    "        }\n",
    "        $forkManager->finish;\n",
    "    }\n",
    "    $forkManager->wait_all_children;\n",
    "    sleep(120);\n",
    "    system(\"pkill -f exonerate-server\");\n",
    "    sleep(120);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes several hours to a day to run all these, assuming all goes well and you have > 30 cores to work with.\n",
    "\n",
    "After this comes one of the trickier parts. We'll process all of these exonerate files to harvest the putative contiguous genomic region sequences and align to the proteins. For instance, rat protein ENSRNOP00000046335 was mapped to the rat chromosome 7 between base pairs 143497108 and 143489162. Additionally, exonerate uncovered 8 introns spread throughout the alignment. The first intron starts at about bp 143496581 and ends at bp 143495791. So, we'll designate the first intron as running from 143496581-143497108. We want to pull the rat genomic DNA sequence from 143496581-143497108 and align it to the original mouse EST sequence. \n",
    "\n",
    "Let's say this exon sequence aligns at base pairs 10-537 in the mouse EST. We would then code this as rat-inferred splice sites before base 10 and after 537 in the mouse EST. We'll gather all such inferred splice sites for each EST, keeping track of which ones come from which species."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPerl [git]",
   "language": "perl",
   "name": "iperl"
  },
  "language_info": {
   "file_extension": ".pl",
   "mimetype": "text/x-perl",
   "name": "perl",
   "version": "5.20.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
