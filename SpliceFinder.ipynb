{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splicefinder\n",
    "======\n",
    "\n",
    "This is the walkthrough and code that accompanies \"Conservative prediction of intron splice sites for the design of exon-capture arrays.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 1: Download mouse data from Ensembl\n",
    "\n",
    "_________________\n",
    "\n",
    "Connect to the server, navigate to the proper folder, and download data in bash:\n",
    "\n",
    "```bash\n",
    "ssh maven\n",
    "cd /mnt/Data1/spliceFinder\n",
    "mkdir ensembl\n",
    "cd ensembl\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz\n",
    "\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/mus_musculus/cdna/README\n",
    "\n",
    "gunzip Mus_musculus.GRCm38.cdna.all.fa.gz\n",
    "```\n",
    "\n",
    "After downloading the data, `get_fasta_lengths.py --input Mus_musculus.GRCm38.cdna.all.fa` gives the following output:\n",
    "\n",
    "```text\n",
    "Reads:\t\t90,891\n",
    "Bp:\t\t168,812,502\n",
    "Avg. len:\t1,857.30712612\n",
    "STDERR len:\t6.5011432467\n",
    "Min. len:\t9\n",
    "Max. len:\t106,824\n",
    "Median len:\t1,078.0\n",
    "Contigs > 1kb:\t47,261\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These represent the latest set of mouse cDNAs from ENSEMBL. We are first going to randomly subset these into fewer than 90,891, because we are going to run many analyses on these sets, mapping to multiple genomes (which can be slow). Let's see what they look like:\n",
    "\n",
    "```text\n",
    "head --lines 6 Mus_musculus.GRCm38.cdna.all.fa\n",
    ">ENSMUST00000196221 havana_ig_gene:known chromosome:GRCm38:14:54113468:54113476:1 gene:ENSMUSG00000096749 gene_biotype:TR_D_gene transcript_biotype:TR_D_gene\n",
    "ATGGCATAT\n",
    ">ENSMUST00000179664 ensembl_ig_gene:known chromosome:GRCm38:14:54113468:54113478:1 gene:ENSMUSG00000096749 gene_biotype:TR_D_gene transcript_biotype:TR_D_gene\n",
    "ATGGCATATCA\n",
    ">ENSMUST00000177564 ensembl_havana_ig_gene:known chromosome:GRCm38:14:54122226:54122241:1 gene:ENSMUSG00000096176 gene_biotype:TR_D_gene transcript_biotype:TR_D_gene\n",
    "ATCGGAGGGATACGAG\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this output tells us a few things. First of all, some of the transcripts are extremely short. Since the purpose of this method is to infer contiguous genomic sequence chunks long enough to use target enrichment array design, we know we'll want to filter out all cDNAs that are too short to actually yield a target. We'll arbitrarily set this limit at 200bp for now. The following script will output all sequences longer than 199bp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl\n",
    "\n",
    "#filterUnder200.pl\n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use Bio::SeqIO;\n",
    "\n",
    "my $seqIn = Bio::SeqIO->new(-file => \"Mus_musculus.GRCm38.cdna.all.fa\",\n",
    "                            -format => 'fasta');\n",
    "my $seqOut = Bio::SeqIO->new(-file => \">mmGRCm38.cdna.200bpPlus.fa\",\n",
    "                             -format => \"fasta\");\n",
    "\n",
    "while (my $seq = $seqIn->next_seq()) {\n",
    "    if ($seq->length() > 199) {\n",
    "        $seqOut->write_seq($seq);\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, we have:\n",
    "\n",
    "```text\n",
    "get_fasta_lengths.py --input mmGRCm38.cdna.200bpPlus.fa \n",
    "Reads:          90,060\n",
    "Bp:             168,702,266\n",
    "Avg. len:       1,873.22080835\n",
    "STDERR len:     6.53762906167\n",
    "Min. len:       200\n",
    "Max. len:       106,824\n",
    "Median len:     1,098.0\n",
    "Contigs > 1kb:  47,261\n",
    "```\n",
    "\n",
    "That didn't very many, so we'll have to reduce further. You'll notice in the fasta headers that there is a gene name in the fourth column. Let's find out how many unique gene names there are total:\n",
    "\n",
    "```text\n",
    "grep \"gene:\" mmGRCm38.cdna.200bpPlus.fa | awk '{print $4}' | uniq -c | wc -l\n",
    "30722\n",
    "```\n",
    "\n",
    "Randomly choosing one transcript from each gene name seems like one good way to reduce the dataset without losing genomic coverage. But choosing the longest cDNA from each gene name might give us better success at mapping to other genomes. Let's do that with the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl\n",
    "\n",
    "# longestFromGenes.pl\n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use Bio::SeqIO;\n",
    "\n",
    "\n",
    "my %seqHash;\n",
    "my $seqIn1 = Bio::SeqIO->new(-file => \"mmGRCm38.cdna.200bpPlus.fa\",\n",
    "                             -format => \"fasta\");\n",
    "my $seqOut = Bio::SeqIO->new(-file => \">mmGRCm38.cdna.longestFromGenes.fa\",\n",
    "                             -format => \"fasta\");\n",
    "\n",
    "while (my $seq = $seqIn1->next_seq()) {\n",
    "    if ($seq->desc() =~ /.*gene\\:(\\S+)\\s/) {\n",
    "        # Each transcript is associated with a gene name, and has a\n",
    "        # hash value equal to its length\n",
    "        my $geneName = $1;\n",
    "        $seqHash{$geneName}{$seq->display_id()} = $seq;\n",
    "    }\n",
    "}\n",
    "\n",
    "foreach my $gene (sort keys %seqHash) {\n",
    "    my $longestID;\n",
    "    my $longestLength = 0;\n",
    "    foreach my $transcript (sort keys %{$seqHash{$gene}}) {\n",
    "        if ($seqHash{$gene}{$transcript}->length() > $longestLength) {\n",
    "            $longestID = $transcript;\n",
    "            $longestLength = $seqHash{$gene}{$transcript}->length();\n",
    "        }\n",
    "    }\n",
    "    $seqOut->write_seq($seqHash{$gene}{$longestID})\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should get the list down to 30,722, and the average length should go up (it was 1,873 bp before).\n",
    "\n",
    "```text\n",
    "get_fasta_lengths.py --input mmGRCm38.cdna.longestFromGenes.fa \n",
    "Reads:          30,722\n",
    "Bp:             73,817,860\n",
    "Avg. len:       2,402.76869995\n",
    "STDERR len:     13.0889977284\n",
    "Min. len:       200\n",
    "Max. len:       106,824\n",
    "Median len:     1,734.0\n",
    "Contigs > 1kb:  20,279\n",
    "```\n",
    "\n",
    "Looking good! I think 30,722 transcripts is still a little high though, so I will subset the dataset down to 10,000 transcripts randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use List::Util qw/shuffle/;\n",
    "\n",
    "#random10k.pl\n",
    "\n",
    "my $seqIn = Bio::SeqIO->new(-file => \"mmGRCm38.cdna.longestFromGenes.fa\",\n",
    "                            -format => \"fasta\");\n",
    "my $seqOut = Bio::SeqIO->new(-file => \">mmGRCm38.cdna.rand10kLongest.fa\",\n",
    "                            -format => \"fasta\");\n",
    "\n",
    "my @seqArray;\n",
    "while (my $seq = $seqIn->next_seq()) {\n",
    "    push(@seqArray, $seq);\n",
    "}\n",
    "\n",
    "my @shuffledSeqs = shuffle(@seqArray);\n",
    "\n",
    "my $counter = 0;\n",
    "while ($counter < 10000) {\n",
    "    $seqOut->write_seq($shuffledSeqs[$counter]);\n",
    "    $counter++;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That should give us 10,000 transcripts from 10,000 distinct genes scattered throughout the mouse genome.\n",
    "\n",
    "```text\n",
    "get_fasta_lengths.py --input mmGRCm38.cdna.rand10kLongest.fa\n",
    "Reads:\t\t10,000\n",
    "Bp:\t\t23,940,240\n",
    "Avg. len:\t2,394.024\n",
    "STDERR len:\t21.8914472689\n",
    "Min. len:\t200\n",
    "Max. len:\t22,489\n",
    "Median len:\t1,732.0\n",
    "Contigs > 1kb:\t6,651\n",
    "```\n",
    "\n",
    "Excellent. Now we're ready to set up some mapping. In this experiment, we're going to want to map to approximately 10 genomes of varying sequence divergence from the mouse genome. For now, let's try the following genomes:\n",
    "  1. Rat (_Rattus norvegicus_)\n",
    "  2. Human (_Homo sapiens_)\n",
    "  3. Pig (_Sus scrofa_)\n",
    "  4. Elephant (_Loxodonta_africana_)\n",
    "  5. Playtpus (_Ornithorynchus anatinus_)\n",
    "  6. Chicken (_Gallus gallus_)\n",
    "  7. _Xenopus tropicalis_\n",
    "  8. _Anolis carolinensis_\n",
    "  9. Coelacanth (_Latimeria chalumnae_)\n",
    "  10. Puffer fish (_Takifugu rubripes_)\n",
    "  11. Sea lamprey (*Petromyzon marinus*)\n",
    "  12. Sea urchin (*Strongylocentrotus purpuratus*)\n",
    "\n",
    "\n",
    "Let's download those genomes, getting the unmasked primary assembly if possible, otherwise taking the unmasked top-level assembly:\n",
    "\n",
    "```bash\n",
    "cd ..\n",
    "mkdir genomes\n",
    "cd genomes\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/rattus_norvegicus/dna/Rattus_norvegicus.Rnor_6.0.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/sus_scrofa/dna/Sus_scrofa.Sscrofa10.2.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/loxodonta_africana/dna/Loxodonta_africana.loxAfr3.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/ornithorhynchus_anatinus/dna/Ornithorhynchus_anatinus.OANA5.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/gallus_gallus/dna/Gallus_gallus.Galgal4.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/xenopus_tropicalis/dna/Xenopus_tropicalis.JGI_4.2.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/anolis_carolinensis/dna/Anolis_carolinensis.AnoCar2.0.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/latimeria_chalumnae/dna/Latimeria_chalumnae.LatCha1.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/takifugu_rubripes/dna/Takifugu_rubripes.FUGU4.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/petromyzon_marinus/dna/Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.fa.gz\n",
    "wget ftp://ftp.ensemblgenomes.org/pub/metazoa/release-26/fasta/strongylocentrotus_purpuratus/dna/Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.fa.gz\n",
    "\n",
    "gunzip *.gz\n",
    "```\n",
    "\n",
    "We'll also need the full collection of protein sequences from these organisms:\n",
    "```bash\n",
    "mkdir proteins\n",
    "cd proteins\n",
    "\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/rattus_norvegicus/pep/Rattus_norvegicus.Rnor_6.0.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/homo_sapiens/pep/Homo_sapiens.GRCh38.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/sus_scrofa/pep/Sus_scrofa.Sscrofa10.2.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/loxodonta_africana/pep/Loxodonta_africana.loxAfr3.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/ornithorhynchus_anatinus/pep/Ornithorhynchus_anatinus.OANA5.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/gallus_gallus/pep/Gallus_gallus.Galgal4.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/xenopus_tropicalis/pep/Xenopus_tropicalis.JGI_4.2.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/anolis_carolinensis/pep/Anolis_carolinensis.AnoCar2.0.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/latimeria_chalumnae/pep/Latimeria_chalumnae.LatCha1.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/takifugu_rubripes/pep/Takifugu_rubripes.FUGU4.pep.all.fa.gz\n",
    "wget ftp://ftp.ensembl.org/pub/release-80/fasta/petromyzon_marinus/pep/Petromyzon_marinus.Pmarinus_7.0.pep.all.fa.gz\n",
    "wget ftp://ftp.ensemblgenomes.org/pub/metazoa/release-26/fasta/strongylocentrotus_purpuratus/pep/Strongylocentrotus_purpuratus.GCA_000002235.2.26.pep.all.fa.gz\n",
    "\n",
    "gunzip *\n",
    "```\n",
    "\n",
    "We're going to use exonerate protein2genome to map all of these proteins to their respective genomes.\n",
    "```bash\n",
    "cd ../\n",
    "\n",
    "fasta2esd --softmask no Loxodonta_africana.loxAfr3.dna.toplevel.fa Loxodonta_africana.loxAfr3.dna.toplevel.esd\n",
    "fasta2esd --softmask no Ornithorhynchus_anatinus.OANA5.dna.toplevel.fa Ornithorhynchus_anatinus.OANA5.dna.toplevel.esd\n",
    "fasta2esd --softmask no Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.fa Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.esd\n",
    "fasta2esd --softmask no Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.fa Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.esd\n",
    "fasta2esd --softmask no Takifugu_rubripes.FUGU4.dna.toplevel.fa Takifugu_rubripes.FUGU4.dna.toplevel.esd\n",
    "fasta2esd --softmask no Latimeria_chalumnae.LatCha1.dna.toplevel.fa Latimeria_chalumnae.LatCha1.dna.toplevel.esd\n",
    "fasta2esd --softmask no Anolis_carolinensis.AnoCar2.0.dna.toplevel.fa Anolis_carolinensis.AnoCar2.0.dna.toplevel.esd\n",
    "fasta2esd --softmask no Xenopus_tropicalis.JGI_4.2.dna.toplevel.fa Xenopus_tropicalis.JGI_4.2.dna.toplevel.esd\n",
    "fasta2esd --softmask no Gallus_gallus.Galgal4.dna.toplevel.fa Gallus_gallus.Galgal4.dna.toplevel.esd\n",
    "fasta2esd --softmask no Sus_scrofa.Sscrofa10.2.dna.toplevel.fa Sus_scrofa.Sscrofa10.2.dna.toplevel.esd\n",
    "fasta2esd --softmask no Homo_sapiens.GRCh38.dna.primary_assembly.fa Homo_sapiens.GRCh38.dna.primary_assembly.esd\n",
    "fasta2esd --softmask no Rattus_norvegicus.Rnor_6.0.dna.toplevel.fa Rattus_norvegicus.Rnor_6.0.dna.toplevel.esd\n",
    "\n",
    "esd2esi Loxodonta_africana.loxAfr3.dna.toplevel.esd Loxodonta_africana.loxAfr3.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Ornithorhynchus_anatinus.OANA5.dna.toplevel.esd Ornithorhynchus_anatinus.OANA5.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.esd Strongylocentrotus_purpuratus.GCA_000002235.2.26.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.esd Petromyzon_marinus.Pmarinus_7.0.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Takifugu_rubripes.FUGU4.dna.toplevel.esd Takifugu_rubripes.FUGU4.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Latimeria_chalumnae.LatCha1.dna.toplevel.esd Latimeria_chalumnae.LatCha1.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Anolis_carolinensis.AnoCar2.0.dna.toplevel.esd Anolis_carolinensis.AnoCar2.0.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Xenopus_tropicalis.JGI_4.2.dna.toplevel.esd Xenopus_tropicalis.JGI_4.2.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Gallus_gallus.Galgal4.dna.toplevel.esd Gallus_gallus.Galgal4.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Sus_scrofa.Sscrofa10.2.dna.toplevel.esd Sus_scrofa.Sscrofa10.2.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Homo_sapiens.GRCh38.dna.primary_assembly.esd Homo_sapiens.GRCh38.dna.primary_assembly.trans.esi --translate yes --memorylimit 25600\n",
    "esd2esi Rattus_norvegicus.Rnor_6.0.dna.toplevel.esd Rattus_norvegicus.Rnor_6.0.dna.toplevel.trans.esi --translate yes --memorylimit 25600\n",
    "```\n",
    "\n",
    "This indexing will take several hours. We want to map the orthologous proteins from each species to their own reference genomes. So, the next step is to find the orthologous proteins from each species. We'll need to make blast databases from each protein set first:\n",
    "```bash\n",
    "cd proteins\n",
    "for i in *.pep.all.fa; do makeblastdb -in $i -dbtype prot; done\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPerl [git]",
   "language": "perl",
   "name": "iperl"
  },
  "language_info": {
   "file_extension": ".pl",
   "mimetype": "text/x-perl",
   "name": "perl",
   "version": "5.20.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
